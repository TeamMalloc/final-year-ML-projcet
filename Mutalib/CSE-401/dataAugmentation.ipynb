{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fdd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4c6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifing the path to the dataset directory\n",
    "#data_dir = pathlib.Path(\"D:/NEUB/MachineLearning/ThesisProject/x-rayImages/chest_xray/train\")\n",
    "data_dir = pathlib.Path(\"file:///D:/NEUB-Info/Thesis-Project/chest_xray/train/\")\n",
    "\n",
    "normal_dir = data_dir / \"NORMAL\"\n",
    "pneumonia_dir = data_dir / \"PNEUMONIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18b510f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#counting the total images\n",
    "image_count_normal = len(list(normal_dir.glob('*.jpeg')))\n",
    "image_count_pneumoniya = len(list(pneumonia_dir.glob('*.jpeg')))\n",
    "print(image_count_normal)\n",
    "print(image_count_pneumoniya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c956730b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11152\\2885951181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#printing the first image of normal---------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnormal_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*.jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg_normal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimg_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#printing the first image of pneumoniya---------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#printing the first image of normal---------\n",
    "normal_images = list(normal_dir.glob('*.jpeg'))\n",
    "img_normal = Image.open(normal_images[0])\n",
    "img_normal.show()\n",
    "#printing the first image of pneumoniya---------\n",
    "pneumonia_images = list(pneumonia_dir.glob('*.jpeg'))\n",
    "img_pneumoniya = Image.open(pneumonia_images[0])\n",
    "img_pneumoniya.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef102ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data ---------\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "val_dir = pathlib.Path(\"D:/NEUB/MachineLearning/ThesisProject/x-rayImages/chest_xray/val\")\n",
    "\n",
    "#loading traing data set\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a95dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doading validation data set\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  val_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_names = train_ds.class_names\n",
    "print(cls_names)\n",
    "cls_names_val = val_ds.class_names\n",
    "print(cls_names_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f815bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve the training performance--------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e35be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation model--------------\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    layers.RandomCrop(height=img_height, width=img_width),\n",
    "    layers.RandomHeight(factor=0.1),\n",
    "    layers.RandomWidth(factor=0.1),\n",
    "    layers.RandomContrast(factor=0.1),\n",
    "    #layers.Lambda(lambda x: tf.image.rgb_to_grayscale(x)),\n",
    "    #layers.Lambda(lambda x: tf.math.subtract(tf.constant(255.0), x))\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying data augmentation to the training data set\n",
    "augmented_train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize a specific augmented image\n",
    "sample_image = next(iter(train_ds))[0][6] # choose a specific image from the training dataset\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "fig.suptitle(\"Augmented Images--\")\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i == 0:\n",
    "        # First image is the original image\n",
    "        ax.imshow(sample_image.numpy().astype(\"uint8\"))\n",
    "        ax.set_title(\"Original\")\n",
    "    else:\n",
    "        # Apply the corresponding transformation to the image if the transformation index is within the range of available transformations\n",
    "        if i - 1 < len(data_augmentation.layers):\n",
    "            augmented_image = data_augmentation(sample_image[tf.newaxis, ...], training=True)\n",
    "            ax.imshow(tf.squeeze(augmented_image).numpy().astype(\"uint8\"))\n",
    "            ax.set_title(data_augmentation.layers[i-1].name)\n",
    "        else:\n",
    "            # No more available transformations to apply, so leave the axis blank\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74742d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_original_images = train_ds.cardinality().numpy()*batch_size\n",
    "print(\"Total number of images:\",num_original_images)\n",
    "num_transformations = 8\n",
    "total_num_augmented_images = num_original_images * num_transformations\n",
    "print(\"Total number of augmented images:\",total_num_augmented_images)\n",
    "num_batches = train_ds.__len__()\n",
    "print(\"the total number of batches: \",num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993e2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34dd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
